{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c210974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('./src') # Add src directory to Python path\n",
    "\n",
    "from data_preprocessing import preprocess_data, split_data\n",
    "from modeling import train_evaluate_regression_model, train_evaluate_classification_model\n",
    "from model_interpretation import plot_shap_summary, get_feature_importance\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegression # For classification task\n",
    "from sklearn.ensemble import RandomForestClassifier # For classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e1cc43",
   "metadata": {},
   "source": [
    "- --- Load Data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480a226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/raw/historical_insurance_claims.csv')\n",
    "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b12398",
   "metadata": {},
   "source": [
    "- --- 1. Claim Severity Prediction (Regression) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad4e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Claim Severity Prediction Model ---\")\n",
    "# Filter for policies with claims\n",
    "df_claims_only = df[df['TotalClaims'] > 0].copy()\n",
    "\n",
    "# Define target and features for Claim Severity\n",
    "target_severity = 'TotalClaims'\n",
    "# List features to exclude. Be careful not to include features that leak information about the target.\n",
    "# 'CalculatedPremiumPerTerm' could be a target or a feature. For claim severity, it might be a strong feature.\n",
    "# For optimal premium, it would be a target.\n",
    "features_to_exclude_severity = ['UnderwrittenCoverID', 'PolicyID', 'TransactionDate', 'PostalCode',\n",
    "                               'TotalPremium', 'CalculatedPremiumPerTerm', # Can be strong features\n",
    "                               'ClaimOccurred', 'ClaimFrequency', 'Margin', 'LossRatio'] # Exclude derived claim metrics\n",
    "\n",
    "X_severity_raw, y_severity, preprocessor_severity, severity_features = \\\n",
    "    preprocess_data(df_claims_only, target_severity, features_to_exclude=features_to_exclude_severity)\n",
    "\n",
    "# Transform features\n",
    "X_severity_transformed = preprocessor_severity.fit_transform(X_severity_raw)\n",
    "# Get feature names after one-hot encoding if needed for SHAP\n",
    "feature_names_severity = preprocessor_severity.get_feature_names_out()\n",
    "\n",
    "\n",
    "# Split data\n",
    "X_train_sev, X_test_sev, y_train_sev, y_test_sev = split_data(\n",
    "    pd.DataFrame(X_severity_transformed, columns=feature_names_severity), y_severity\n",
    ")\n",
    "\n",
    "# Train and Evaluate Models\n",
    "models_severity = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost Regressor': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results_severity = {}\n",
    "for name, model in models_severity.items():\n",
    "    trained_model, metrics = train_evaluate_regression_model(model, X_train_sev, y_train_sev, X_test_sev, y_test_sev, name)\n",
    "    results_severity[name] = {'model': trained_model, 'metrics': metrics}\n",
    "\n",
    "# Compare Models\n",
    "print(\"\\n--- Claim Severity Model Comparison ---\")\n",
    "for name, res in results_severity.items():\n",
    "    print(f\"{name}: RMSE={res['metrics']['rmse']:.4f}, R2={res['metrics']['r2']:.4f}\")\n",
    "\n",
    "# Feature Importance and Interpretability for the best-performing model (e.g., XGBoost)\n",
    "best_severity_model = results_severity['XGBoost Regressor']['model']\n",
    "plot_shap_summary(best_severity_model, X_test_sev, feature_names_severity, plot_type='bar')\n",
    "plot_shap_summary(best_severity_model, X_test_sev, feature_names_severity, plot_type='dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3a5e8",
   "metadata": {},
   "source": [
    "- --- 2. Premium Optimization (Regression - predicting CalculatedPremiumPerTerm) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b484e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Premium Optimization Model (Predicting CalculatedPremiumPerTerm) ---\")\n",
    "target_premium = 'CalculatedPremiumPerTerm'\n",
    "features_to_exclude_premium = ['UnderwrittenCoverID', 'PolicyID', 'TransactionDate', 'PostalCode',\n",
    "                               'TotalClaims', 'TotalPremium', # Exclude actual claims and aggregated premiums\n",
    "                               'ClaimOccurred', 'ClaimFrequency', 'Margin', 'LossRatio'] # Exclude derived metrics\n",
    "\n",
    "X_premium_raw, y_premium, preprocessor_premium, premium_features = \\\n",
    "    preprocess_data(df, target_premium, features_to_exclude=features_to_exclude_premium)\n",
    "\n",
    "X_premium_transformed = preprocessor_premium.fit_transform(X_premium_raw)\n",
    "feature_names_premium = preprocessor_premium.get_feature_names_out()\n",
    "\n",
    "X_train_prem, X_test_prem, y_train_prem, y_test_prem = split_data(\n",
    "    pd.DataFrame(X_premium_transformed, columns=feature_names_premium), y_premium\n",
    ")\n",
    "\n",
    "models_premium = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost Regressor': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results_premium = {}\n",
    "for name, model in models_premium.items():\n",
    "    trained_model, metrics = train_evaluate_regression_model(model, X_train_prem, y_train_prem, X_test_prem, y_test_prem, name)\n",
    "    results_premium[name] = {'model': trained_model, 'metrics': metrics}\n",
    "\n",
    "print(\"\\n--- Premium Optimization Model Comparison ---\")\n",
    "for name, res in results_premium.items():\n",
    "    print(f\"{name}: RMSE={res['metrics']['rmse']:.4f}, R2={res['metrics']['r2']:.4f}\")\n",
    "\n",
    "# Feature Importance for Premium Optimization\n",
    "best_premium_model = results_premium['XGBoost Regressor']['model']\n",
    "plot_shap_summary(best_premium_model, X_test_prem, feature_names_premium, plot_type='bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3591ed",
   "metadata": {},
   "source": [
    "- --- 3. Advanced Task: Probability of Claim Prediction (Classification) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aadef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Probability of Claim Prediction Model ---\")\n",
    "df_clf = df.copy()\n",
    "df_clf['ClaimOccurred'] = (df_clf['TotalClaims'] > 0).astype(int) # Target for classification\n",
    "\n",
    "target_clf = 'ClaimOccurred'\n",
    "features_to_exclude_clf = ['UnderwrittenCoverID', 'PolicyID', 'TransactionDate', 'PostalCode',\n",
    "                           'TotalClaims', 'TotalPremium', 'CalculatedPremiumPerTerm',\n",
    "                           'ClaimFrequency', 'ClaimSeverity', 'Margin', 'LossRatio']\n",
    "\n",
    "X_clf_raw, y_clf, preprocessor_clf, clf_features = \\\n",
    "    preprocess_data(df_clf, target_clf, features_to_exclude=features_to_exclude_clf)\n",
    "\n",
    "X_clf_transformed = preprocessor_clf.fit_transform(X_clf_raw)\n",
    "feature_names_clf = preprocessor_clf.get_feature_names_out()\n",
    "\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data(\n",
    "    pd.DataFrame(X_clf_transformed, columns=feature_names_clf), y_clf\n",
    ")\n",
    "\n",
    "models_clf = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, solver='liblinear'),\n",
    "    'Random Forest Classifier': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost Classifier': XGBRegressor(objective='binary:logistic', random_state=42) # XGBoost can do classification\n",
    "}\n",
    "\n",
    "results_clf = {}\n",
    "for name, model in models_clf.items():\n",
    "    if \"XGBoost Classifier\" == name: # Need to use specific classification eval for XGBoost\n",
    "         trained_model, metrics = train_evaluate_classification_model(model, X_train_clf, y_train_clf, X_test_clf, y_test_clf, name)\n",
    "    else:\n",
    "         trained_model, metrics = train_evaluate_classification_model(model, X_train_clf, y_train_clf, X_test_clf, y_test_clf, name)\n",
    "    results_clf[name] = {'model': trained_model, 'metrics': metrics}\n",
    "\n",
    "print(\"\\n--- Probability of Claim Model Comparison ---\")\n",
    "for name, res in results_clf.items():\n",
    "    print(f\"{name}: Accuracy={res['metrics']['accuracy']:.4f}, F1-Score={res['metrics']['f1']:.4f}\")\n",
    "\n",
    "# Feature Importance for Claim Probability\n",
    "best_clf_model = results_clf['XGBoost Classifier']['model']\n",
    "plot_shap_summary(best_clf_model, X_test_clf, feature_names_clf, plot_type='bar')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
